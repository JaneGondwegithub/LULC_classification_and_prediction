{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0",
      "metadata": {
        "id": "0"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gee-community/geemap/blob/master/docs/notebooks/00_ee_auth_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/></a>\n",
        "\n",
        "\n",
        "## Earth Engine Automatic Authentication on Google Colab\n",
        "\n",
        "### Step 1: Locating the Earth Engine Token\n",
        "\n",
        "1. Locate the Earth Engine token on your computer by navigating to the following file path based on your operating system:\n",
        "\n",
        "    - Windows: C:\\\\Users\\\\USERNAME\\\\.config\\\\earthengine\\\\credentials\n",
        "    - Linux: /home/USERNAME/.config/earthengine/credentials\n",
        "    - MacOS: /Users/USERNAME/.config/earthengine/credentials\n",
        "\n",
        "2. Open the credentials file and copy the entire content to the clipboard.\n",
        "\n",
        "    **Note:** Ensure that you do not share the content of the credentials file with others to prevent unauthorized access to your Earth Engine account.\n",
        "\n",
        "### Step 2: Creating the Secret in Google Colab\n",
        "\n",
        "1. Open your Google Colab notebook and click on the `secrets` tab.\n",
        "2. Create a new secret with the name `EARTHENGINE_TOKEN`.\n",
        "3. Paste the content from the clipboard into the `Value` input box of the created secret.\n",
        "4. Toggle the button on the left to allow notebook access to the secret.\n",
        "\n",
        "![](https://i.imgur.com/Z9R08uU.png)\n",
        "\n",
        "### Step 3: Installing the Required Version of geemap\n",
        "\n",
        "Ensure that you have installed geemap version 0.29.3 or later, as only these versions support the automatic authentication feature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1",
      "metadata": {
        "id": "1"
      },
      "outputs": [],
      "source": [
        "%pip install -U geemap"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2",
      "metadata": {
        "id": "2"
      },
      "source": [
        "### Step 4: Automatic Authentication with geemap\n",
        "\n",
        "To automatically authenticate Earth Engine using the EARTHENGINE_TOKEN in your Google Colab notebook, run the following code:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Import required libraries\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "import timm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import shap\n",
        "from google.cloud import storage\n",
        "from google.colab import userdata # Import userdata to access secrets\n",
        "import ee # Import Earth Engine\n",
        "import os\n",
        "import logging\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# Authenticate Earth Engine using the secret\n",
        "try:\n",
        "    ee.Initialize(project='your-earthengine-project') # Replace with your Earth Engine project ID\n",
        "    logging.info('Earth Engine authentication successful.')\n",
        "except Exception as e:\n",
        "    logging.error(f'Earth Engine authentication failed: {e}')\n",
        "\n",
        "# Configuration\n",
        "DATA_DIR = 'gs://your-bucket/esri_patches'  # Replace with your GCS bucket\n",
        "STATS_PATH = '/content/drive/MyDrive/esri_normalization_stats.npy'  # Path to normalization stats\n",
        "OUTPUT_DIR = '/content/drive/MyDrive/lulc_experiment'  # Save models and results\n",
        "BATCH_SIZE = 16\n",
        "LEARNING_RATE = 0.001\n",
        "EPOCHS = 20\n",
        "PATIENCE = 5  # Early stopping threshold\n",
        "NUM_CLASSES = 9\n",
        "IMG_SIZE = 224\n",
        "BANDS = 6  # Blue, Green, Red, NIR, SWIR1, SWIR2\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "logging.info(f'Using device: {DEVICE}')\n",
        "\n",
        "# LULC class names\n",
        "CLASS_NAMES = ['Water', 'Trees', 'Flooded Vegetation', 'Crops', 'Built Area',\n",
        "               'Bare Ground', 'Snow/Ice', 'Clouds', 'Rangeland']\n",
        "\n",
        "# 1. Data Loading and Preprocessing\n",
        "class ESRIDataset(Dataset):\n",
        "    def __init__(self, tfrecord_files, transform=None):\n",
        "        self.tfrecord_files = tfrecord_files\n",
        "        self.transform = transform\n",
        "        self.dataset = self._load_tfrecords()\n",
        "\n",
        "    def _load_tfrecords(self):\n",
        "        dataset = tf.data.TFRecordDataset(self.tfrecord_files)\n",
        "        def parse_fn(example):\n",
        "            feature_desc = {\n",
        "                'patch': tf.io.FixedLenFeature([IMG_SIZE * IMG_SIZE * BANDS], tf.float32),\n",
        "                'label': tf.io.FixedLenFeature([], tf.int64)\n",
        "            }\n",
        "            example = tf.io.parse_single_example(example, feature_desc)\n",
        "            patch = tf.reshape(example['patch'], [IMG_SIZE, IMG_SIZE, BANDS])\n",
        "            label = example['label']\n",
        "            return patch, label\n",
        "        return dataset.map(parse_fn).shuffle(1000)\n",
        "\n",
        "    def __len__(self):\n",
        "        return sum(1 for _ in self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        patch, label = next(iter(self.dataset.skip(idx).take(1)))\n",
        "        patch = patch.numpy()\n",
        "        label = label.numpy()\n",
        "        if self.transform:\n",
        "            patch = self.transform(patch)\n",
        "        return torch.tensor(patch, dtype=torch.float32).permute(2, 0, 1), label\n",
        "\n",
        "# Load normalization stats\n",
        "stats = np.load(STATS_PATH, allow_pickle=True).item()\n",
        "mean, std = stats['mean'], stats['std']\n",
        "logging.info(f'Normalization stats - Mean: {mean}, Std: {std}')\n",
        "\n",
        "# Preprocessing transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Normalize(mean=mean, std=std)\n",
        "])\n",
        "\n",
        "# Load dataset splits\n",
        "def get_tfrecord_files(data_dir, split='train'):\n",
        "    client = storage.Client()\n",
        "    bucket = client.bucket(data_dir.split('gs://')[1])\n",
        "    blobs = bucket.list_blobs(prefix=f'esri_patches/{split}')\n",
        "    return [f'gs://{data_dir.split(\"gs://\")[1]}/{blob.name}' for blob in blobs]\n",
        "\n",
        "train_files = get_tfrecord_files(DATA_DIR, 'train')  # ~18,900 patches\n",
        "val_files = get_tfrecord_files(DATA_DIR, 'val')      # ~4,050 patches\n",
        "test_files = get_tfrecord_files(DATA_DIR, 'test')    # ~4,050 patches\n",
        "\n",
        "train_dataset = ESRIDataset(train_files, transform=transform)\n",
        "val_dataset = ESRIDataset(val_files, transform=transform)\n",
        "test_dataset = ESRIDataset(test_files, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, num_workers=2)\n",
        "\n",
        "# 2. Model Setup\n",
        "def create_model(model_name, pretrained=True, num_classes=NUM_CLASSES):\n",
        "    model = timm.create_model(model_name, pretrained=pretrained, num_classes=num_classes)\n",
        "    return model.to(DEVICE)\n",
        "\n",
        "# Models to evaluate\n",
        "models = {\n",
        "    'resnet50': create_model('resnet50', pretrained=True),\n",
        "    'vit_base_patch16_224': create_model('vit_base_patch16_224', pretrained=True),\n",
        "    'vit_large_patch16_224': create_model('vit_large_patch16_224', pretrained=True),\n",
        "    'swin_small_patch4_window7_224': create_model('swin_small_patch4_window7_224', pretrained=True),\n",
        "    'swin_large_patch4_window7_224': create_model('swin_large_patch4_window7_224', pretrained=True)\n",
        "}\n",
        "\n",
        "# 3. Training Function\n",
        "def train_model(model, model_name, train_loader, val_loader, fine_tune='full', epochs=EPOCHS):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9)\n",
        "\n",
        "    # Partial fine-tuning: Freeze lower layers\n",
        "    if fine_tune == 'partial':\n",
        "        if 'vit' in model_name:\n",
        "            for param in model.blocks[:-2].parameters():  # Freeze all but last 2 blocks\n",
        "                param.requires_grad = False\n",
        "        elif 'swin' in model_name:\n",
        "            for param in model.layers[:-1].parameters():  # Freeze all but last layer\n",
        "                param.requires_grad = False\n",
        "        elif 'resnet' in model_name:\n",
        "            for param in model.layer1.parameters():  # Freeze first layer\n",
        "                param.requires_grad = False\n",
        "            for param in model.layer2.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "        train_loss /= len(train_loader)\n",
        "        logging.info(f'{model_name} ({fine_tune}) Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
        "\n",
        "        # Early stopping\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            patience_counter = 0\n",
        "            torch.save(model.state_dict(), f'{OUTPUT_DIR}/{model_name}_{fine_tune}.pth')\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= PATIENCE:\n",
        "                logging.info(f'Early stopping at epoch {epoch+1} for {model_name}_{fine_tune}')\n",
        "                break\n",
        "\n",
        "    return model\n",
        "\n",
        "# 4. Evaluation Function\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    preds, true_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            preds.extend(predicted.cpu().numpy())\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = accuracy_score(true_labels, preds)\n",
        "    f1 = f1_score(true_labels, preds, average='weighted')\n",
        "    # mIoU: Simplified for single-label classification\n",
        "    iou_scores = []\n",
        "    for cls in range(NUM_CLASSES):\n",
        "        intersection = sum((np.array(true_labels) == cls) & (np.array(preds) == cls))\n",
        "        union = sum((np.array(true_labels) == cls) | (np.array(preds) == cls))\n",
        "        iou_scores.append(intersection / union if union > 0 else 0)\n",
        "    miou = np.mean(iou_scores)\n",
        "\n",
        "    return {'accuracy': accuracy, 'f1_score': f1, 'miou': miou}\n",
        "\n",
        "# 5. Explainability Analysis\n",
        "def get_attention_maps(model, model_name, images):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        if 'vit' in model_name:\n",
        "            # ViT: Access attention weights from the last block\n",
        "            outputs = model.forward_features(images)\n",
        "            attn_weights = model.blocks[-1].attn.attn_weights  # Shape: (batch, heads, patches, patches)\n",
        "            return attn_weights.mean(dim=1)  # Average over heads\n",
        "        elif 'swin' in model_name:\n",
        "            # Swin: Access attention weights from the last layer\n",
        "            outputs = model.forward_features(images)\n",
        "            attn_weights = model.layers[-1].blocks[-1].attn.attn_weights\n",
        "            return attn_weights.mean(dim=1)\n",
        "    return None\n",
        "\n",
        "def plot_attention_map(attn_weights, image, label, class_name):\n",
        "    attn_map = attn_weights[0].cpu().numpy().reshape(int(IMG_SIZE/16), int(IMG_SIZE/16))\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.imshow(image[:3].permute(1, 2, 0).cpu().numpy() * std[:3] + mean[:3], interpolation='nearest')\n",
        "    plt.imshow(attn_map, cmap='jet', alpha=0.5, extent=(0, IMG_SIZE, IMG_SIZE, 0))\n",
        "    plt.title(f'Attention Map: {class_name}')\n",
        "    plt.axis('off')\n",
        "    plt.savefig(f'{OUTPUT_DIR}/attention_map_{class_name}.png')\n",
        "    plt.close()\n",
        "\n",
        "def compute_shap_values(model, images, background_samples=50):\n",
        "    model.eval()\n",
        "    explainer = shap.DeepExplainer(model, images[:background_samples])\n",
        "    shap_values = explainer.shap_values(images)\n",
        "    return shap_values\n",
        "\n",
        "# 6. Main Experiment\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "results = {}\n",
        "for model_name in models.keys():\n",
        "    for fine_tune in ['full', 'partial']:\n",
        "        logging.info(f'Training {model_name} with {fine_tune} fine-tuning...')\n",
        "        model = create_model(model_name, pretrained=True)\n",
        "        model = train_model(model, model_name, train_loader, val_loader, fine_tune)\n",
        "        metrics = evaluate_model(model, test_loader)\n",
        "        results[f'{model_name}_{fine_tune}'] = metrics\n",
        "        logging.info(f'{model_name}_{fine_tune}: Accuracy={metrics[\"accuracy\"]:.3f}, F1={metrics[\"f1_score\"]:.3f}, mIoU={metrics[\"miou\"]:.3f}')\n",
        "\n",
        "        # Explainability: Analyze one test sample\n",
        "        images, labels = next(iter(test_loader))\n",
        "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "        attn_weights = get_attention_maps(model, model_name, images)\n",
        "        if attn_weights is not None:\n",
        "            plot_attention_map(attn_weights, images[0], labels[0], CLASS_NAMES[labels[0]])\n",
        "        shap_values = compute_shap_values(model, images)\n",
        "        shap.image_plot(shap_values, images.cpu().numpy() * std + mean, labels=[CLASS_NAMES[l] for l in labels], show=False)\n",
        "        plt.savefig(f'{OUTPUT_DIR}/shap_{model_name}_{fine_tune}.png')\n",
        "        plt.close()\n",
        "\n",
        "# 7. Save and Visualize Results\n",
        "results_df = pd.DataFrame(results).T\n",
        "results_df.to_csv(f'{OUTPUT_DIR}/experiment_results.csv')\n",
        "logging.info(f'Results saved to {OUTPUT_DIR}/experiment_results.csv')\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x=results_df.index, y=results_df['accuracy'])\n",
        "plt.xticks(rotation=45)\n",
        "plt.title('Model Accuracy Comparison on ESRI 10m LULC Dataset')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.tight_layout()\n",
        "plt.savefig(f'{OUTPUT_DIR}/accuracy_comparison.png')\n",
        "plt.close()\n",
        "logging.info(f'Accuracy plot saved to {OUTPUT_DIR}/accuracy_comparison.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "AAsLeQfKb4Ms",
        "outputId": "d6018c1c-a9d5-45c7-d237-e516731db357"
      },
      "id": "AAsLeQfKb4Ms",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "\n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}